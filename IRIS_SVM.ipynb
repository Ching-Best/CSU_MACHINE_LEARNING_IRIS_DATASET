{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=20, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, :2]             # Get the first 2 columns.\n",
    "Y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "#Split the set into training and testing\n",
    "\n",
    "clf = svm.SVC(C=0.8, kernel='rbf', gamma=20, decision_function_shape='ovr')\n",
    "'''\n",
    "one-versus-one, that is1-v-1 SVMs, OVO SVMs, pairwise\n",
    "For each two catalogy, it will produce a SVM，thus in k samples we have to\n",
    "design k(k-1)/2 number of SVM.\n",
    "A=B=C=D=0; \n",
    "(A, B)-classifier if A win,then A=A+1;otherwise,B=B+1; \n",
    "(A,C)-classifer if A win,then A=A+1;otherwise, C=C+1; \n",
    "(C,D)-classifer if A win,then C=C+1;otherwise,D=D+1; \n",
    "The decision is the Max(A,B,C,D) \n",
    "one-versus-rest \n",
    "'''\n",
    "clf.fit(x_train, y_train.ravel())\n",
    "#clf = svm.SVC(C=0.1, kernel='linear', decision_function_shape='ovr')\n",
    "# rsdial basis function kernel k(xi,yi) = exp(-r||xi - yi||^2) r>0 r = 1/2sigma^2\n",
    "# k(xi,xj) = (xi,xj)^d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set precision: 0.8761904761904762\n",
      "Test set precision: 0.6666666666666666\n",
      "decision_function:\n",
      " [[-0.26496148  2.31320556  0.95175593]\n",
      " [-0.46460103  1.0069957   2.45760533]\n",
      " [-0.34406807  0.88669571  2.45737235]\n",
      " [-0.33663974  0.94499968  2.39164007]\n",
      " [-0.26092765  0.80359001  2.45733763]\n",
      " [-0.41227069  2.45224614  0.96002455]\n",
      " [-0.24916617  0.79185614  2.45731002]\n",
      " [-0.46658731  1.04419605  2.42239126]\n",
      " [-0.35231227  2.47502681  0.87728546]\n",
      " [-0.39306788  0.93582612  2.45724176]\n",
      " [-0.40608284  0.93841843  2.46766442]\n",
      " [-0.43745964  1.1734242   2.26403544]\n",
      " [-0.45742019  1.18117017  2.27625003]\n",
      " [-0.45426871  1.04748839  2.40678032]\n",
      " [-0.46460103  1.0069957   2.45760533]\n",
      " [-0.35218559  2.30517692  1.04700868]\n",
      " [ 2.47234131 -0.32113958  0.84879827]\n",
      " [-0.45733812  2.33815922  1.1191789 ]\n",
      " [-0.3821427   2.45738211  0.92476059]\n",
      " [-0.32999198  2.47836427  0.85162771]\n",
      " [-0.35008225  2.4574273   0.89265494]\n",
      " [-0.43536684  1.09667167  2.33869516]\n",
      " [-0.33054945  0.87308262  2.45746683]\n",
      " [ 2.45747335 -0.31420736  0.85673402]\n",
      " [ 2.43817793 -0.30852738  0.87034945]\n",
      " [-0.39442842  0.93691202  2.4575164 ]\n",
      " [-0.35405309  2.43841445  0.91563864]\n",
      " [ 2.45729636 -0.31008202  0.85278566]\n",
      " [ 2.30365824 -0.25443138  0.95077314]\n",
      " [-0.45739651  1.04385458  2.41354193]\n",
      " [ 2.45745742 -0.31426306  0.85680565]\n",
      " [-0.42486791  1.08141845  2.34344946]\n",
      " [-0.36290675  2.31997674  1.04293001]\n",
      " [ 2.45748465 -0.31413718  0.85665253]\n",
      " [-0.37700205  2.36590616  1.01109589]\n",
      " [-0.25226674  0.7949563   2.45731045]\n",
      " [-0.38350612  2.46700428  0.91650183]\n",
      " [ 2.45745664 -0.31486878  0.85741214]\n",
      " [-0.32796939  0.87054024  2.45742915]\n",
      " [-0.46190057  1.02617076  2.43572981]\n",
      " [-0.46460103  1.0069957   2.45760533]\n",
      " [-0.42547014  0.96801077  2.45745936]\n",
      " [ 2.45743514 -0.31409245  0.85665731]\n",
      " [ 2.4572889  -0.31412239  0.85683348]\n",
      " [-0.39230642  0.91391987  2.47838655]\n",
      " [-0.34406807  0.88669571  2.45737235]\n",
      " [ 2.28197178 -0.23951179  0.95754001]\n",
      " [-0.43871763  1.02742995  2.41128768]\n",
      " [ 2.49825525 -0.33376617  0.83551092]\n",
      " [-0.41801203  2.31388105  1.10413098]\n",
      " [-0.45739651  1.04385458  2.41354193]\n",
      " [ 2.45746315 -0.31419231  0.85672916]\n",
      " [ 2.45741565 -0.31420561  0.85678996]\n",
      " [-0.28856091  0.8176081   2.47095281]\n",
      " [ 2.47074512 -0.32019014  0.84944502]\n",
      " [ 2.45757719 -0.31424336  0.85666617]\n",
      " [ 2.45511874 -0.31421287  0.85909413]\n",
      " [-0.31127347  2.40919351  0.90207996]\n",
      " [-0.4545839   0.9800576   2.4745263 ]\n",
      " [-0.24927355  0.79183965  2.45743389]\n",
      " [ 2.47074512 -0.32019014  0.84944502]\n",
      " [ 2.5        -0.33384527  0.83384527]\n",
      " [ 2.45734026 -0.31381689  0.85647663]\n",
      " [-0.41893755  2.47467347  0.94426408]\n",
      " [-0.47401419  1.13058533  2.34342886]\n",
      " [ 2.45739401 -0.3140774   0.85668339]\n",
      " [ 2.45734571 -0.31403818  0.85669247]\n",
      " [-0.46033253  0.98664402  2.47368852]\n",
      " [ 2.45729636 -0.31008202  0.85278566]\n",
      " [-0.24927184  0.79183287  2.45743896]\n",
      " [-0.42385768  2.25000776  1.17384992]\n",
      " [-0.24915611  0.7918198   2.45733632]\n",
      " [-0.47951907  1.07594629  2.40357278]\n",
      " [ 2.4017853  -0.29935902  0.89757373]\n",
      " [-0.44304655  1.05010471  2.39294184]\n",
      " [ 2.31496122 -0.25957915  0.94461793]\n",
      " [-0.24911364  0.79174941  2.45736423]\n",
      " [ 2.45743514 -0.31409245  0.85665731]\n",
      " [ 2.45831184 -0.31506352  0.85675167]\n",
      " [-0.2494809   0.7921166   2.45736429]\n",
      " [ 2.45738474 -0.31409768  0.85671294]\n",
      " [-0.41605645  0.9587184   2.45733806]\n",
      " [-0.41893755  2.47467347  0.94426408]\n",
      " [-0.45733812  2.33815922  1.1191789 ]\n",
      " [-0.46442091  2.41392789  1.05049302]\n",
      " [-0.42018542  0.96275506  2.45743037]\n",
      " [-0.4589104   1.18046274  2.27844765]\n",
      " [-0.45742019  1.18117017  2.27625003]\n",
      " [-0.4589104   1.18046274  2.27844765]\n",
      " [ 2.45757449 -0.31404498  0.85647049]\n",
      " [-0.35231227  2.47502681  0.87728546]\n",
      " [-0.47951907  1.07594629  2.40357278]\n",
      " [-0.45733812  2.33815922  1.1191789 ]\n",
      " [ 2.47487938 -0.32214884  0.84726946]\n",
      " [-0.42947085  1.18992656  2.23954429]\n",
      " [-0.30839736  2.45744276  0.8509546 ]\n",
      " [-0.36335926  2.31920273  1.04415652]\n",
      " [-0.37148005  2.41647845  0.95500159]\n",
      " [ 2.45690978 -0.31070864  0.85379886]\n",
      " [ 2.48467806 -0.32631184  0.84163377]\n",
      " [ 2.5        -0.33384527  0.83384527]\n",
      " [-0.43710037  0.9795783   2.45752207]\n",
      " [-0.45733812  2.33815922  1.1191789 ]\n",
      " [-0.24924098  0.79166915  2.45757183]\n",
      " [ 2.48795549 -0.32889021  0.84093472]]\n",
      "\n",
      "predict:\n",
      " [1 2 2 2 2 1 2 2 1 2 2 2 2 2 2 1 0 1 1 1 1 2 2 0 0 2 1 0 0 2 0 2 1 0 1 2 1\n",
      " 0 2 2 2 2 0 0 2 2 0 2 0 1 2 0 0 2 0 0 0 1 2 2 0 0 0 1 2 0 0 2 0 2 1 2 2 0\n",
      " 2 0 2 0 0 2 0 2 1 1 1 2 2 2 2 0 1 2 1 0 2 1 1 1 0 0 0 2 1 2 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWe wold like to find a transformation of the data T:R^n to R^n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training set precision:',clf.score(x_train, y_train))# accuracy\n",
    "y_hat = clf.predict(x_train)\n",
    "print('Test set precision:',clf.score(x_test, y_test))\n",
    "y_hat = clf.predict(x_test)\n",
    "\n",
    "print('decision_function:\\n', clf.decision_function(x_train))\n",
    "#Every column is the distance to every catalogy\n",
    "print('\\npredict:\\n', clf.predict(x_train)) # Which target/catagory\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min(), X[:, 0].max() # range of row 0\n",
    "x2_min, x2_max = X[:, 1].min(), X[:, 1].max() # range of row 1\n",
    "x1, x2 = np.mgrid[x1_min:x1_max:200j, x2_min:x2_max:200j] #training points\n",
    "grid_test = np.stack((x1.flat, x2.flat), axis=1) # testing points\n",
    "# print 'grid_test = \\n', grid_testgrid_hat = clf.predict(grid_test)      \n",
    "# predict the classifier grid_hat = grid_hat.reshape(x1.shape) \n",
    "'''mgrid() function F(x,y) = x+y\n",
    "Step1 x span to the right\n",
    "[1 1 1]\n",
    "[2 2 2]\n",
    "[3 3 3]\n",
    "step 2 y span to the down side\n",
    "[4 5 6]\n",
    "[4 5 6]\n",
    "[4 5 6]\n",
    "step 3 \n",
    "[(1,4)(1,5)(1,6)]\n",
    "[(2,4)(2,5)(2,6)]\n",
    "[(3,4)(3,5)(3,6)]\n",
    "step 4 plug in (xi,yi) \n",
    "'''\n",
    "'''\n",
    "We wold like to find a transformation of the data T:R^n to R^n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
